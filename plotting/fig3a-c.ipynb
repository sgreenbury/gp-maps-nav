{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import glob as glob\n",
    "\n",
    "OUT_PATH = \"outs_final_nee\"\n",
    "os.makedirs(OUT_PATH, exist_ok=True)\n",
    "\n",
    "DATA_PATH = \"ny/afv/prelim/20210101_SWAPS\"\n",
    "\n",
    "\n",
    "ONE_COL_MM = 890 * 2/3\n",
    "\n",
    "nee_fs = 7\n",
    "font = {\n",
    "    \"family\": \"sans-serif\",\n",
    "    \"sans-serif\": [\"Helvetica\"],\n",
    "    \"weight\": \"normal\",\n",
    "    \"size\": nee_fs,\n",
    "}\n",
    "plt.matplotlib.rc(\"font\", **font)\n",
    "plt.matplotlib.rcParams['pdf.fonttype'] = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prefixes = {\n",
    "    \"HP3x3x3s\":f\"{DATA_PATH}/HP3x3x3s/\",\n",
    "    \"HP5x5s\":f\"{DATA_PATH}/HP5x5s/\",\n",
    "    \"RNA12\":f\"{DATA_PATH}/RNA12\",\n",
    "    \"s_2_8\":f\"{DATA_PATH}/s_2_8\"   \n",
    "}\n",
    "\n",
    "labels = {\n",
    "    \"HP3x3x3s\":\"HP3x3x3\",\n",
    "    \"HP5x5s\":\"HP5x5\",\n",
    "    \"RNA12\":\"RNA12\",\n",
    "    \"s_2_8\":r\"$S_{2,8}$\"   \n",
    "}\n",
    "\n",
    "sizes = {\n",
    "    \"HP3x3x3s\":2**27,\n",
    "    \"HP5x5s\":2**25,\n",
    "    \"RNA12\":4**12,\n",
    "    \"s_2_8\":8**8 \n",
    "}\n",
    "\n",
    "lengths = {\n",
    "    \"HP3x3x3s\":27,\n",
    "    \"HP5x5s\":25,\n",
    "    \"RNA12\":12,\n",
    "    \"s_2_8\": 8 \n",
    "}\n",
    "\n",
    "\n",
    "linspaces = {\n",
    "    \"HP3x3x3s\":np.linspace(0,2**27,101).astype(int),\n",
    "    \"HP5x5s\":np.linspace(0,2**25,101).astype(int),\n",
    "    \"RNA12\":np.linspace(0,4**12,101).astype(int),\n",
    "    \"s_2_8\":np.linspace(0,8**8,101).astype(int),\n",
    "}\n",
    "colors  = ['#9e0142','#d53e4f','#f46d43','#fdae61','#fee08b','#e6f598','#abdda4','#66c2a5','#3288bd','#5e4fa2']\n",
    "colors[1] =\"C0\"\n",
    "colors[2] =\"C1\"\n",
    "colors[3] =\"C2\"\n",
    "colors_map = {}\n",
    "colors_map[\"HP_3x3x3s\"] = colors[1]\n",
    "colors_map[\"HP3x3x3s\"] = colors[1]\n",
    "colors_map[\"HP_5x5s\"] = colors[3]\n",
    "colors_map[\"HP5x5s\"] = colors[3]\n",
    "colors_map[\"s_2_8\"] = colors[0]\n",
    "colors_map[\"RNA_12\"] = colors[2]\n",
    "colors_map[\"RNA12\"] = colors[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno_dict = {\n",
    "    0:\"phenotype\",\n",
    "    1:\"n_components\",\n",
    "    2:\"Frequency\", # volume_0\n",
    "    3:\"surface_0\", # Sum of component surfaces\n",
    "    4:\"volume_1\", # ( f_p * (K-1) * L * r_p )/(double)2\n",
    "    5:\"surface_1\",\n",
    "    6:\"robustness\",\n",
    "    7:\"evolvability_wagner\",\n",
    "    8:\"evolvability_cowperthwaite\",\n",
    "    9:\"evolvability_wagner_nond\",\n",
    "    10:\"evolvability_cowperthwaite_nond\",\n",
    "    11:\"S_1\", # f_p * (1 - r_p)\n",
    "    12:\"S_2\", # S_1 = V_1 * 2(1/r_p - 1)\n",
    "    13:\"surface_unique\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 1e7\n",
    "dfs = []\n",
    "for prefix_key, prefix in prefixes.items():\n",
    "    files = [file for file in glob.glob(os.path.join(prefix, \"stats*.txt\")) if \"swaps\" not in file]\n",
    "    for file in files:\n",
    "        swap_index = int(re.findall(\"s(\\d+).txt\", file)[0])\n",
    "        swaps = linspaces[prefix_key][swap_index]\n",
    "        df = pd.read_csv(file, sep=\"\\t\")\n",
    "        df_pheno = pd.read_csv(file.replace(f\"stats{swap_index}.txt\", f\"NC/phenotype_stats{swap_index}.txt\"), sep=\"\\t\", header=None, names=pheno_dict.values())\n",
    "        df[\"u+v\"] = df[\"u_size\"] + df[\"v_size\"]\n",
    "        df[\"threshold\"] = (df[\"u+v\"] > threshold)*1\n",
    "        df[\"freq_mean\"] = (df_pheno[\"Frequency\"]/sizes[\"HP5x5s\"]).mean()\n",
    "        df[\"rob_mean\"] = (df_pheno[\"robustness\"]).mean()\n",
    "        df[\"freq_std\"] = (df_pheno[\"Frequency\"]/sizes[\"HP5x5s\"]).std()\n",
    "        df[\"rob_std\"] = (df_pheno[\"robustness\"]).std()\n",
    "        df[\"rob-freq-ratio_mean\"] = ((df_pheno[\"robustness\"])/(df_pheno[\"Frequency\"]/sizes[\"HP5x5s\"])).mean()\n",
    "        df[\"rob-freq-ratio_std\"] = ((df_pheno[\"robustness\"])/(df_pheno[\"Frequency\"]/sizes[\"HP5x5s\"])).std()\n",
    "        df[\"swap_index\"] = swap_index\n",
    "        df[\"swaps\"] = linspaces[prefix_key][swap_index]\n",
    "        df[\"swaps_prop\"] = df[\"swaps\"]/sizes[prefix_key]\n",
    "        df[\"GP map\"] = prefix_key\n",
    "        dfs.append(df)\n",
    "    \n",
    "dfs = pd.concat(dfs).reset_index(drop=True)\n",
    "\n",
    "# Only keep non-aborted\n",
    "dfs = dfs[dfs[\"threshold\"]==0]\n",
    "\n",
    "# Robustness to frequency mean\n",
    "x_el = \"rob-freq-ratio_mean\"\n",
    "dfs[\"correlations\"]=np.nan\n",
    "for gp_map in dfs[\"GP map\"].unique():\n",
    "    df = dfs[dfs[\"GP map\"]==gp_map]\n",
    "    rob_freq_max = df[x_el].max()\n",
    "    dfs.loc[df.index, \"correlations\"] = (1/rob_freq_max)*(dfs.loc[df.index, x_el] - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get correlations, dimensionality and ruggedness\n",
    "prefixes = {\n",
    "    \"HP3x3x3s\":\"HP3x3x3s/\",\n",
    "    \"HP5x5s\":\"HP5x5s/\",\n",
    "    \"RNA12\":\"RNA12\",\n",
    "    \"s_2_8\":\"s_2_8\"   \n",
    "}\n",
    "threshold = 1e7\n",
    "dfs_corr = []\n",
    "for prefix_key, prefix in prefixes.items():\n",
    "    files = [file for file in glob.glob(os.path.join(DATA_PATH, prefix, \"stats*.txt\")) if \"swaps\" not in file]\n",
    "    for file in files:\n",
    "        swap_index = int(re.findall(\"s(\\d+).txt\", file)[0])\n",
    "        swaps = linspaces[prefix_key][swap_index]\n",
    "        df = pd.read_csv(file, sep=\"\\t\")\n",
    "        df_pheno = pd.read_csv(file.replace(f\"stats{swap_index}.txt\", f\"NC/phenotype_stats{swap_index}.txt\"), sep=\"\\t\", header=None, names=pheno_dict.values())\n",
    "        df[\"u+v\"] = df[\"u_size\"] + df[\"v_size\"]\n",
    "        df[\"threshold\"] = (df[\"u+v\"] > threshold)*1\n",
    "        df[\"freq_mean\"] = (df_pheno[\"Frequency\"]/sizes[prefix_key]).mean()\n",
    "        df[\"rob_mean\"] = (df_pheno[\"robustness\"]).mean()\n",
    "        df[\"freq_std\"] = (df_pheno[\"Frequency\"]/sizes[prefix_key]).std()\n",
    "        df[\"rob_std\"] = (df_pheno[\"robustness\"]).std()\n",
    "        df[\"rob-freq-ratio_mean\"] = ((df_pheno[\"robustness\"])/(df_pheno[\"Frequency\"]/sizes[prefix_key])).mean()\n",
    "        df[\"rob-freq-ratio_std\"] = ((df_pheno[\"robustness\"])/(df_pheno[\"Frequency\"]/sizes[prefix_key])).std()\n",
    "        df[\"swap_index\"] = swap_index\n",
    "        df[\"swaps\"] = linspaces[prefix_key][swap_index]\n",
    "        df[\"swaps_prop\"] = df[\"swaps\"]/sizes[prefix_key]\n",
    "        df[\"GP map\"] = prefix_key\n",
    "        dfs_corr.append(df)\n",
    "    \n",
    "dfs_corr = pd.concat(dfs_corr).reset_index(drop=True)\n",
    "\n",
    "# Only keep non-aborted\n",
    "dfs_corr = dfs_corr[dfs_corr[\"threshold\"]==0]\n",
    "\n",
    "x_el = \"rob-freq-ratio_mean\"\n",
    "dfs_corr[\"correlations\"]=np.nan\n",
    "for gp_map in dfs_corr[\"GP map\"].unique():\n",
    "    df = dfs_corr[dfs_corr[\"GP map\"]==gp_map]\n",
    "    rob_freq_max = np.log10(df[x_el]).max()\n",
    "    dfs_corr.loc[df.index, \"correlations\"] = np.log10(dfs_corr.loc[df.index, x_el])/rob_freq_max\n",
    "\n",
    "\n",
    "# Dimensionality\n",
    "prefixes = {\n",
    "    \"HP3x3x3s\":\"HP3x3x3s/\",\n",
    "    \"HP5x5s\":\"HP5x5s/\",\n",
    "    \"RNA12\":\"RNA_12\",\n",
    "    \"s_2_8\":\"s_2_8\"\n",
    "}\n",
    "\n",
    "threshold = 1e7\n",
    "dfs_dim = []\n",
    "big_prefix = f\"{DATA_PATH}/../../20201231_variable_dimensionality_long_ruggedness_HP-corrected_dim/\"\n",
    "for prefix_key, prefix in prefixes.items():\n",
    "    files = [file for file in glob.glob(os.path.join(big_prefix, prefix, \"stats_*.txt\")) if \"swaps\" not in file]\n",
    "    for file in files:\n",
    "        df = pd.read_csv(file, sep=\"\\t\")\n",
    "        dim = int(re.findall(\"D-(\\d+)\", file)[0])\n",
    "        df[\"dim\"] = dim\n",
    "        df[\"ruggedness\"] = df[\"downhill_count\"]/(df[\"uphill_count\"]+df[\"downhill_count\"])\n",
    "        df[\"u+v\"] = df[\"u_size\"] + df[\"v_size\"]\n",
    "        df[\"threshold\"] = (df[\"u+v\"] > threshold)*1\n",
    "        df[\"GP map\"] = prefix_key\n",
    "        dfs_dim.append(df)\n",
    "dfs_dim = pd.concat(dfs_dim).reset_index(drop=True)\n",
    "dfs_dim = dfs_dim[dfs_dim[\"threshold\"]==0]\n",
    "\n",
    "# Ruggedness\n",
    "prefixes = {\n",
    "    \"HP3x3x3s\":\"HP3x3x3s/\",\n",
    "    \"HP5x5s\":\"HP5x5s/\",\n",
    "    \"RNA12\":\"RNA_12\",\n",
    "    \"s_2_8\":\"s_2_8\"\n",
    "}\n",
    "\n",
    "threshold = 1e7\n",
    "dfs_rug = []\n",
    "big_prefix = f\"{DATA_PATH}/../../20201231_variable_dimensionality_long_ruggedness_HP-corrected_rug/\"\n",
    "for prefix_key, prefix in prefixes.items():\n",
    "    files = [file for file in glob.glob(os.path.join(big_prefix, prefix, \"stats_*.txt\")) if \"swaps\" not in file]\n",
    "    for file in files:\n",
    "        df = pd.read_csv(file, sep=\"\\t\")\n",
    "        dim = int(re.findall(\"D-(\\d+)\", file)[0])\n",
    "        df[\"dim\"] = dim\n",
    "        df[\"ruggedness\"] = df[\"downhill_count\"]/(df[\"uphill_count\"]+df[\"downhill_count\"])\n",
    "        df[\"u+v\"] = df[\"u_size\"] + df[\"v_size\"]\n",
    "        df[\"threshold\"] = (df[\"u+v\"] > threshold)*1\n",
    "        df[\"GP map\"] = prefix_key\n",
    "        dfs_rug.append(df)\n",
    "dfs_rug = pd.concat(dfs_rug).reset_index(drop=True)\n",
    "dfs_rug = dfs_rug[(dfs_rug[\"threshold\"]==0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMBINED\n",
    "# fig = plt.figure(1, figsize=(138/25 * .6, 290/25 * .6))\n",
    "ONE_COL_MM = 890 * 2/3\n",
    "figsize = (ONE_COL_MM / 250, 290/128 * ONE_COL_MM / 250)\n",
    "\n",
    "fig = plt.figure(1, figsize=figsize)\n",
    "\n",
    "# fs = \"x-small\"\n",
    "fs = nee_fs\n",
    "fs = 5\n",
    "# -------------\n",
    "# FIG. 3A\n",
    "ax = fig.add_subplot(311)\n",
    "\n",
    "# x_el = \"rob-freq-ratio_mean\"\n",
    "x_el = \"correlations\"\n",
    "\n",
    "for gp_map in sizes.keys():        \n",
    "    df = dfs_corr[dfs_corr[\"GP map\"]==gp_map]\\\n",
    "    .groupby(x_el)[\"Fittest_found?\"]\\\n",
    "    .agg([\"mean\", lambda x: x.std(ddof=1)/np.sqrt(len(x))])\\\n",
    "    .reset_index()\\\n",
    "    .sort_values(x_el)\\\n",
    "    .rename(columns={\"<lambda_0>\":\"SE\"})\n",
    "    \n",
    "    ax.plot(df[x_el], df[\"mean\"], color=colors_map[gp_map], label=labels[gp_map])\n",
    "        \n",
    "    extra=1.\n",
    "    intercept=0.01\n",
    "\n",
    "ax.set_xlim(-0.05, 1.05)\n",
    "ax.set_ylim(-0.05, 1.1)\n",
    "ax.set_ylabel(r'Navigability, $\\left<\\psi\\right>$')\n",
    "ax.set_xlabel(r'Neutral correlations, $c$')\n",
    "\n",
    "ax.legend(loc=\"upper left\", prop={\"size\":fs}, frameon=True)\n",
    "\n",
    "# FIG. 3B\n",
    "\n",
    "ax = fig.add_subplot(312)\n",
    "\n",
    "for gp_map in sizes.keys():\n",
    "    df = dfs_dim[dfs_dim[\"GP map\"]==gp_map]\\\n",
    "    .groupby(\"dim\")[\"Fittest_found?\"]\\\n",
    "    .agg([\"mean\", lambda x: x.std(ddof=1)/np.sqrt(len(x))])\\\n",
    "    .reset_index()\\\n",
    "    .sort_values(\"dim\")\\\n",
    "    .rename(columns={\"<lambda_0>\":\"SE\"})\n",
    "    \n",
    "    ax.plot(df[\"dim\"]/lengths[gp_map], df[\"mean\"], color=colors_map[gp_map], label=labels[gp_map])\n",
    "        \n",
    "    extra=1.\n",
    "    intercept=0.01\n",
    "\n",
    "ax.set_xlim(0, 1.0)\n",
    "ax.set_xlim(-0.05, 1.05)\n",
    "ax.set_ylim(-0.05, 1.1)\n",
    "ax.set_ylabel(r'Navigability, $\\left<\\psi\\right>$')\n",
    "ax.set_xlabel(r'Relative dimensionality, $d$')\n",
    "\n",
    "ax.legend(loc=\"upper left\", prop={\"size\":fs}, frameon=True)\n",
    "\n",
    "# FIG. 3B\n",
    "ax = fig.add_subplot(313)\n",
    "\n",
    "for gp_map in sizes.keys():\n",
    "    df = dfs_rug[dfs_rug[\"GP map\"]==gp_map]\\\n",
    "    .groupby(\"dim\")[\"ruggedness\"]\\\n",
    "    .agg([\"mean\", lambda x: x.std(ddof=1)/np.sqrt(len(x))])\\\n",
    "    .reset_index()\\\n",
    "    .sort_values(\"dim\")\\\n",
    "    .rename(columns={\"<lambda_0>\":\"SE\"})\n",
    "    \n",
    "    ax.plot(df[\"dim\"]/lengths[gp_map], df[\"mean\"], color=colors_map[gp_map], label=labels[gp_map])\n",
    "    \n",
    "    extra=1.\n",
    "    intercept=0.01\n",
    "ax.set_xlim(-0.05, 1.05)\n",
    "ax.set_ylim(-0.05, 1.1)\n",
    "ax.set_ylabel(r'Ruggedness, $\\left<\\kappa\\right>$')\n",
    "ax.set_xlabel(r'Relative dimensionality, $d$')\n",
    "\n",
    "ax.legend(loc=\"upper right\", prop={\"size\":fs}, frameon=True)\n",
    "\n",
    "fig.subplots_adjust(hspace=0.35)\n",
    "\n",
    "fig.savefig(os.path.join(OUT_PATH, \"fig3.pdf\"), transparent=True, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate minimum and maximum correlations\n",
    "df_corr_random = None\n",
    "for gp_map in sizes.keys():        \n",
    "    df = dfs_corr[dfs_corr[\"GP map\"]==gp_map]\\\n",
    "    .groupby(x_el)[\"Fittest_found?\"]\\\n",
    "    .agg([\"mean\", lambda x: x.std(ddof=1)/np.sqrt(len(x))])\\\n",
    "    .reset_index()\\\n",
    "    .sort_values(x_el)\\\n",
    "    .rename(columns={\"<lambda_0>\":\"SE\"})\n",
    "    df[\"GP map\"] = gp_map\n",
    "    df_corr_random = pd.concat([df_corr_random, df], axis=0)\n",
    "\n",
    "    \n",
    "df_corr_random[\"abs_corr\"] = df_corr_random[\"correlations\"].abs()\n",
    "\n",
    "for keep in [\"first\", \"last\"]:\n",
    "    print(\n",
    "        (\n",
    "            df_corr_random\n",
    "            .sort_values([\"abs_corr\", \"GP map\"])\n",
    "            .drop_duplicates(subset=[\"GP map\"], keep=keep)\n",
    "            .drop(columns=[\"abs_corr\"])\n",
    "            .round(3)\n",
    "        ).to_markdown()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
