{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "extra_path = \"ny/fRNA/fRNA/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_results(L, threshold=100, no_neut=True, hamming=False, old=True):\n",
    "    if not hamming:\n",
    "        if no_neut:\n",
    "            if old:\n",
    "                files3 = glob.glob(\n",
    "                    f\"{extra_path}180414_r_assignment_parallel_L{L}_2e6_NO-NEUTRAL-MUTS/\"\n",
    "                    f\"180414_r_assignment_parallel_L{L}_2e6/data_out/*stats_*\"\n",
    "                )\n",
    "                files3 = [\n",
    "                    el\n",
    "                    for el in files3\n",
    "                    if re.findall(r\"stats_L\\d{1,2}_\\d{1,2}\\.txt\", el)\n",
    "                ]\n",
    "            else:\n",
    "                files3 = [\n",
    "                    el\n",
    "                    for el in glob.glob(\n",
    "                        \"gp_maps_nav_data/data/raw_output/landscape/frna/20000/20220423_outs_mono_no-neut-mat/random/**/stats*txt\",\n",
    "                        recursive=True,\n",
    "                    )\n",
    "                    if f\"l{L}\" in el\n",
    "                ]\n",
    "        else:\n",
    "            files3 = glob.glob(\n",
    "                f\"{extra_path}180414_r_assignment_parallel_L{L}_2e6/data_out/*stats_*\"\n",
    "            )\n",
    "            files3 = [\n",
    "                el for el in files3 if re.findall(r\"stats_L\\d{1,2}_\\d{1,2}\\.txt\", el)\n",
    "            ]\n",
    "\n",
    "    else:\n",
    "        if no_neut:\n",
    "            files3 = [\n",
    "                el\n",
    "                for el in glob.glob(\n",
    "                    \"gp_maps_nav_data/data/raw_output/landscape/frna/20000/20220423_outs_mono_no-neut-mat/hamming/**/stats*txt\",\n",
    "                    recursive=True,\n",
    "                )\n",
    "                if f\"l{L}\" in el\n",
    "            ]\n",
    "        else:\n",
    "            files3 = [\n",
    "                el\n",
    "                for el in glob.glob(\n",
    "                    \"gp_maps_nav_data/data/raw_output/landscape/frna/20000/20220423_outs_mono/hamming/**/stats*txt\",\n",
    "                    recursive=True,\n",
    "                )\n",
    "                if f\"l{L}\" in el\n",
    "            ]\n",
    "    df = pd.concat([pd.read_csv(el, sep=\"\\t\") for el in files3]).reset_index(drop=True)\n",
    "\n",
    "    df[\"aborted\"] = (\n",
    "        (df[\"u_size\"] + df[\"v_size\"])\n",
    "        > ((df[\"u_size\"] + df[\"v_size\"]).max() - threshold)\n",
    "    ) * 1\n",
    "\n",
    "    df[\"aborted\"] = (df[\"Fittest_found?\"].eq(0) & ~df[\"u_size\"].eq(0)).mul(1)\n",
    "\n",
    "    df[\"L\"] = L\n",
    "\n",
    "    df[\"uv_size\"] = df[\"u_size\"] + df[\"v_size\"]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load no neutral mutations and neutral mutations results\n",
    "# Not neutral, Random\n",
    "df_no_neut = pd.concat(\n",
    "    [load_results(el, no_neut=True, old=False) for el in [20, 25, 30, 35, 40]]\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# Neutral, Random\n",
    "df_neut = pd.concat(\n",
    "    [load_results(el, no_neut=False) for el in [20, 25, 30, 35, 40]]\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# Load Hamming resutls\n",
    "df_neut_ham = pd.concat(\n",
    "    [\n",
    "        load_results(el, no_neut=False, hamming=True, threshold=100)\n",
    "        for el in [20, 25, 30, 35, 40]\n",
    "    ]\n",
    ").reset_index(drop=True)\n",
    "df_no_neut_ham = pd.concat(\n",
    "    [\n",
    "        load_results(el, no_neut=True, hamming=True, threshold=100)\n",
    "        for el in [20, 25, 30, 35, 40]\n",
    "    ]\n",
    ").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get navigability estimates, number of unique targets tested and number of phenotypes\n",
    "# in fRNA database at a given length L\n",
    "def get_psi(df):\n",
    "    df_neut_complete = df[df[\"aborted\"] != 1]\n",
    "    df_neut_complete = (\n",
    "        df_neut_complete.groupby(\"L\")[[\"Fittest_found?\"]]\n",
    "        .agg([\"mean\", lambda x: x.std(ddof=1) / len(x) ** 0.5])\n",
    "        .T.reset_index(drop=True)\n",
    "        .T\n",
    "    )\n",
    "    df_neut_complete = df_neut_complete.rename(\n",
    "        columns=dict(zip(df_neut_complete.columns, [\"psi\", \"se\"]))\n",
    "    )\n",
    "    df_neut_complete[\"comb\"] = df_neut_complete.apply(\n",
    "        lambda x: \"${0:.3f} \\pm {1:.3f}$\".format(x[\"psi\"], x[\"se\"]), axis=1\n",
    "    )\n",
    "    return (\n",
    "        df_neut_complete[\"comb\"]\n",
    "        .to_frame()\n",
    "        .rename(columns={\"comb\": r\"$\\left<\\psi\\right>$\"})\n",
    "    )\n",
    "\n",
    "\n",
    "def get_aborted(df):\n",
    "    df_neut_complete = df[df[\"aborted\"] != -1]\n",
    "    df_neut_complete = (\n",
    "        df_neut_complete.groupby(\"L\")[[\"aborted\"]]\n",
    "        .agg([\"mean\", lambda x: x.std(ddof=1) / len(x) ** 0.5])\n",
    "        .T.reset_index(drop=True)\n",
    "        .T\n",
    "    )\n",
    "    df_neut_complete = df_neut_complete.rename(\n",
    "        columns=dict(zip(df_neut_complete.columns, [\"aborted\", \"se\"]))\n",
    "    )\n",
    "    return (\n",
    "        df_neut_complete[\"aborted\"]\n",
    "        .apply(lambda x: f\"{x:.3f}\")\n",
    "        .rename(\"Aborted\")\n",
    "        .to_frame()\n",
    "    )\n",
    "\n",
    "\n",
    "def get_ntargets(df):\n",
    "    return (\n",
    "        df.groupby(\"L\")[\"Target\"]\n",
    "        .apply(lambda x: x.nunique())\n",
    "        .rename(\"Targets\")\n",
    "        .to_frame()\n",
    "    )\n",
    "\n",
    "\n",
    "def get_Np(df):\n",
    "    data = []\n",
    "    for L in df[\"L\"].unique():\n",
    "        pdata = pd.read_csv(\"../frna/data/ps_l\" + str(L) + \".txt\", header=None).rename(\n",
    "            {0: \"phenotype\"}, axis=1\n",
    "        )\n",
    "        data.append([L, len(pdata)])\n",
    "    return pd.DataFrame(data, columns=[\"L\", r\"$N_P$\"]).set_index(\"L\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the final results dataframe\n",
    "def get_df_outs(df_neut, df_no_neut, fitness=\"Random\"):\n",
    "    df_outs = None\n",
    "    names = [\"Neutral mutations\", \"No neutral mutations$^{*}$\"]\n",
    "    for name, df_ in [(names[0], df_neut), (names[1], df_no_neut)]:\n",
    "        df_1 = get_psi(df_)\n",
    "        df_2 = get_aborted(df_)\n",
    "        df_3 = get_ntargets(df_)\n",
    "        df_4 = get_Np(df_)\n",
    "        df_neut_out = pd.concat([df_3, df_4, df_1, df_2], axis=1)\n",
    "        df_outs = pd.concat([df_outs, df_neut_out], axis=1)\n",
    "    df_outs.columns = pd.MultiIndex.from_product([names, df_neut_out.columns.to_list()])\n",
    "    df_outs.insert(0, (\"\", \"Fitness\"), fitness)\n",
    "    df_outs = df_outs.drop(columns=[(\"No neutral mutations$^{*}$\", \"$N_P$\")])\n",
    "    df_outs = df_outs.drop(columns=[\n",
    "        (\"No neutral mutations$^{*}$\", \"Targets\"),\n",
    "        (\"Neutral mutations\", \"Targets\"),\n",
    "    ])\n",
    "    df_outs = (\n",
    "        df_outs.reset_index()\n",
    "        .set_index([(\"\", \"Fitness\"), \"L\", (\"Neutral mutations\", \"$N_P$\")])\n",
    "        .rename_axis(index=[\"Fitness\", \"L\", \"$N_P$\"])\n",
    "    )\n",
    "    df_outs.columns = pd.MultiIndex.from_tuples(\n",
    "        [el if el[1] != \"Aborted\" else (el[0], \"$\\\\alpha$\") for el in df_outs.columns]\n",
    "    )\n",
    "    return df_outs\n",
    "\n",
    "\n",
    "def print_for_paper(df_outs):\n",
    "    pd.options.display.float_format = \"{:,}\".format\n",
    "    print(df_outs.round(3).to_markdown())\n",
    "    pd.options.display.float_format = \"{:,}\".format\n",
    "    print(df_outs.round(3).convert_dtypes().to_latex(\n",
    "        multicolumn_format=\"c\", escape=False\n",
    "    ))\n",
    "\n",
    "\n",
    "df_outs = get_df_outs(df_neut, df_no_neut, fitness=\"Random\")\n",
    "df_outs_ham = get_df_outs(df_neut_ham, df_no_neut_ham, fitness=\"Hamming$^{*}$\")\n",
    "df_all = pd.concat([df_outs, df_outs_ham], axis=0)\n",
    "print_for_paper(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
